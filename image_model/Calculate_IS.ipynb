{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ee59a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "from numpy import ones\n",
    "from numpy import expand_dims\n",
    "from numpy import log\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import exp\n",
    "from numpy.random import shuffle\n",
    "from keras.datasets import cifar10\n",
    "from skimage.transform import resize\n",
    "from numpy import asarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6885c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import utils as vutils\n",
    "from transformer import VQGANTransformer\n",
    "# from utils import load_data, plot_images\n",
    "import sys\n",
    "sys.path.insert(0, './taming-transformers')\n",
    "sys.path.insert(0, './taming-transformers/taming')\n",
    "# import model\n",
    "class TestTransformer:\n",
    "    def __init__(self, args):\n",
    "        self.model = load_transformer(args).to(device=args.device)\n",
    "        \n",
    "        self.score = self.calculate_inception_score(args)\n",
    "\n",
    "                \n",
    "   # def scale_images(self,images, new_shape):\n",
    "    #    images_list = list()\n",
    "     #   for image in images:\n",
    "      #      # resize with nearest neighbor interpolation\n",
    "       #     new_image = resize(image, new_shape, 0)\n",
    "        #    # store\n",
    "         #   images_list.append(new_image)\n",
    "        #return asarray(images_list)\n",
    "    \n",
    "    def load_transformer(args):\n",
    "        model = VQGANTransformer(args)\n",
    "        model.load_checkpoint(args.transformer_checkpoint_path)\n",
    "        model = model.eval()\n",
    "        return model\n",
    "    \n",
    "    def load_testdata(args):\n",
    "        test_data = ImagePaths(args.test_dataset_path, size=256)\n",
    "        test_loader = DataLoader(test_data, batch_size=args.batch_size, shuffle=False)\n",
    "        return test_loader\n",
    "    \n",
    "#     def test(self, args):\n",
    "#         test_dataset = load_data(args)\n",
    "#         with tqdm(range(len(test_dataset))) as pbar:\n",
    "#             for i, imgs in zip(pbar, test_dataset):\n",
    "#                 imgs = imgs.to(device=args.device)\n",
    "#                 for j in range(len(imgs)): #不确定要不要加这个for在batchsize里\n",
    "#                     log, sampled_imgs = self.model.log_images(imgs[j][None])\n",
    "#                     vutils.save_image(log[\"rec\"], os.path.join(\"test\", f\"{epoch}.jpg\"), nrow=4)\n",
    "                    \n",
    "        \n",
    " \n",
    "\n",
    "    def calculate_inception_score(self, args, n_split=10, eps=1E-16):\n",
    "        image = load_testdata(args) ## 改arg里数据来源\n",
    "        image=image.to(device=args.device) #?? 可能不需要\n",
    "        shuffle(test_dataset)\n",
    "        \n",
    "        # enumerate splits of images/predictions\n",
    "        scores = list()\n",
    "        n_part = floor(images.shape[0] / n_split)\n",
    "        for i in range(n_split):\n",
    "        \n",
    "            ix_start, ix_end = i * n_part, (i+1) * n_part\n",
    "            subset = images[ix_start:ix_end]\n",
    "        \n",
    "            subset = subset.astype('float32')\n",
    "            # predict p(y|x)\n",
    "            \n",
    "            log, sampled_imgs = self.model.log_images(subset[:][None])\n",
    "            p_yx = log[\"rec\"] #有可能是2，因为多个图片会多一个维度，rec变为2\n",
    "            \n",
    "            # calculate p(y)\n",
    "            p_y = expand_dims(p_yx.mean(axis=0), 0)\n",
    "            # calculate KL divergence using log probabilities\n",
    "            kl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))\n",
    "            # sum over classes\n",
    "            sum_kl_d = kl_d.sum(axis=1)\n",
    "            # average over images\n",
    "            avg_kl_d = mean(sum_kl_d)\n",
    "            # undo the log\n",
    "            is_score = exp(avg_kl_d)\n",
    "            # store\n",
    "            scores.append(is_score)\n",
    "        # average across images\n",
    "        is_avg, is_std = mean(scores), std(scores)\n",
    "        print('score', is_avg, is_std)\n",
    "        \n",
    "        return is_avg, is_std\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ae4b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=\"VQGAN\")\n",
    "    parser.add_argument('--latent-dim', type=int, default=256, help='Latent dimension n_z.')\n",
    "    parser.add_argument('--image-size', type=int, default=256, help='Image height and width.)')\n",
    "    parser.add_argument('--num-codebook-vectors', type=int, default=1024, help='Number of codebook vectors.')\n",
    "    parser.add_argument('--beta', type=float, default=0.25, help='Commitment loss scalar.')\n",
    "    parser.add_argument('--image-channels', type=int, default=3, help='Number of channels of images.')\n",
    "    parser.add_argument('--dataset-path', type=str, default='./data', help='Path to data.')\n",
    "    parser.add_argument('--checkpoint-path', type=str, default='./checkpoints/last_ckpt.pt', help='Path to vqgan checkpoint.')\n",
    "    parser.add_argument('--device', type=str, default=\"cuda\", help='Which device the training is on')\n",
    "    parser.add_argument('--batch-size', type=int, default=10, help='Input batch size for training.')\n",
    "    parser.add_argument('--epochs', type=int, default=50, help='Number of epochs to train.')\n",
    "    parser.add_argument('--learning-rate', type=float, default=2.25e-05, help='Learning rate.')\n",
    "    parser.add_argument('--beta1', type=float, default=0.5, help='Adam beta param.')\n",
    "    parser.add_argument('--beta2', type=float, default=0.9, help='Adam beta param.')\n",
    "    parser.add_argument('--disc-start', type=int, default=10000, help='When to start the discriminator.')\n",
    "    parser.add_argument('--disc-factor', type=float, default=1., help='Weighting factor for the Discriminator.')\n",
    "    parser.add_argument('--l2-loss-factor', type=float, default=1., help='Weighting factor for reconstruction loss.')\n",
    "    parser.add_argument('--perceptual-loss-factor', type=float, default=1., help='Weighting factor for perceptual loss.')\n",
    "    parser.add_argument('--config-path', type=str, default='./configs/model.yaml', help='Path to configs.')\n",
    "    parser.add_argument('--transformer-checkpoint-path', type=str, default='./checkpoints/last_ckpt.pt', help='Path to transformer checkpoint.')\n",
    "    parser.add_argument('--test-dataset-path', type=str, default='./test', help='Path to test data.')\n",
    "\n",
    "    parser.add_argument('--pkeep', type=float, default=0.5, help='Percentage for how much latent codes to keep.')\n",
    "    parser.add_argument('--sos-token', type=int, default=0, help='Start of Sentence token.')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    args.dataset_path = r\"/home/ygong2832/file/ILSVRC/Data/CLS-LOC/train_sub2\"\n",
    "    args.checkpoint_path = r\"./taming-transformers/logs/vqgan_imagenet_f16_16384/checkpoints/last.ckpt\"\n",
    "    args.config_path = r\"./taming-transformers/logs/vqgan_imagenet_f16_16384/configs/model.yaml\"\n",
    "    args.transformer_checkpoint_path = r\"/home/ygong2832/checkpoints/transformer_epoch_39.pt\"\n",
    "    args.test_dataset_path = r\"/home/ygong2832/file/ILSVRC/Data/CLS-LOC/test_sub\"\n",
    "\n",
    "    testpic = TestTransformer(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c853179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f71f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f850e665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d58a09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# def calculate_inception_score(images, n_split=10, eps=1E-16):\n",
    "    \n",
    "#     model = ae\n",
    "#     # enumerate splits of images/predictions\n",
    "#     scores = list()\n",
    "#     n_part = floor(images.shape[0] / n_split)\n",
    "#     for i in range(n_split):\n",
    "        \n",
    "#         ix_start, ix_end = i * n_part, (i+1) * n_part\n",
    "#         subset = images[ix_start:ix_end]\n",
    "        \n",
    "#         ## for i, imgs in zip(pbar, subset):\n",
    "        \n",
    "#         subset = subset.astype('float32')\n",
    "#         # predict p(y|x)\n",
    "#         p_yx = model.predict(subset)\n",
    "#         # calculate p(y)\n",
    "#         p_y = expand_dims(p_yx.mean(axis=0), 0)\n",
    "#         # calculate KL divergence using log probabilities\n",
    "#         kl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))\n",
    "#         # sum over classes\n",
    "#         sum_kl_d = kl_d.sum(axis=1)\n",
    "#         # average over images\n",
    "#         avg_kl_d = mean(sum_kl_d)\n",
    "#         # undo the log\n",
    "#         is_score = exp(avg_kl_d)\n",
    "#         # store\n",
    "#         scores.append(is_score)\n",
    "#     # average across images\n",
    "#     is_avg, is_std = mean(scores), std(scores)\n",
    "#     return is_avg, is_std\n",
    " \n",
    "\n",
    "\n",
    "# shuffle(X_test)\n",
    "# is_avg, is_std = calculate_inception_score(X_test)\n",
    "# print('score', is_avg, is_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
