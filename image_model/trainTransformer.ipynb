{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d32eee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "Downloading vgg_lpips model from https://heibox.uni-heidelberg.de/f/607503859c864bc1b30b/?dl=1 to taming/modules/autoencoder/lpips/vgg.pth\n",
      "8.19kB [00:00, 362kB/s]                                                         \n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "  0%|                    | 1/390 [00:06<20:25,  3.15s/it, Transformer_Loss=9.48]^C\n"
     ]
    }
   ],
   "source": [
    "!python ./MaskGIT-pytorch/training_transformer.py --batch-size=10 --num-codebook-vectors=16384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d66f4585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"./MaskGIT-pytorch/training_transformer.py\", line 20, in <module>\r\n",
      "    from transformer import VQGANTransformer\r\n",
      "  File \"/home/ygong2832/W4995DL-Final/MaskGIT-pytorch/transformer.py\", line 23, in <module>\r\n",
      "    from models.vqgan import VQModel\r\n",
      "  File \"/home/ygong2832/taming-transformers/taming/models/vqgan.py\", line 8, in <module>\r\n",
      "    from taming.modules.vqvae.quantize import VectorQuantizer2 as VectorQuantizer\r\n",
      "  File \"/home/ygong2832/taming-transformers/taming/modules/vqvae/quantize.py\", line 6, in <module>\r\n",
      "    from einops import rearrange\r\n",
      "ModuleNotFoundError: No module named 'einops'\r\n"
     ]
    }
   ],
   "source": [
    "!python ./MaskGIT-pytorch/training_transformer.py --batch-size=10 --num-codebook-vectors=16384 --epochs=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38fa65c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar 29 04:53:27 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   44C    P0    67W / 149W |      0MiB / 11441MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06e14ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "  3%|▌                     | 10/390 [00:39<26:09,  4.13s/it, Transformer_Loss=7]^C\n",
      "  3%|▌                     | 10/390 [00:43<27:34,  4.35s/it, Transformer_Loss=7]\n",
      "Traceback (most recent call last):\n",
      "  File \"./MaskGIT-pytorch/training_transformer.py\", line 99, in <module>\n",
      "    train_transformer = TrainTransformer(args)\n",
      "  File \"./MaskGIT-pytorch/training_transformer.py\", line 21, in __init__\n",
      "    self.train(args)\n",
      "  File \"./MaskGIT-pytorch/training_transformer.py\", line 33, in train\n",
      "    self.optim.step()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/optim/adamw.py\", line 148, in step\n",
      "    eps=group['eps'])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/optim/_functional.py\", line 139, in adamw\n",
      "    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ./MaskGIT-pytorch/training_transformer.py --batch-size=10 --num-codebook-vectors=16384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3e17230",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.yaml\r\n"
     ]
    }
   ],
   "source": [
    "ls ./taming-transformers/logs/vqgan_imagenet_f16_16384/configs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0bc6492d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "config_path = r\"./taming-transformers/logs/vqgan_imagenet_f16_16384/configs/model.yaml\"\n",
    "config = OmegaConf.load(config_path)\n",
    "config.model.params['n_embed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc3706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import utils as vutils\n",
    "from transformer import VQGANTransformer\n",
    "from utils import load_data, plot_images\n",
    "import sys\n",
    "sys.path.insert(0, '/home/ygong2832/taming-transformers')\n",
    "sys.path.insert(0, '/home/ygong2832/taming-transformers/taming')\n",
    "# import model\n",
    "model = VQGANTransformer(args).to(device=args.device)\n",
    "model.load_state_dict(torch.load('path'))\n",
    "model.eval()\n",
    "# test\n",
    "with tqdm(range(len(test_dataset))) as pbar:\n",
    "    for i, imgs in zip(pbar, test_dataset):\n",
    "        real = imgs.to(device=args.device)\n",
    "        vutils.save_image(real, os.path.join(\"real\", f\"{i}.jpg\"))\n",
    "        logits, target = model(real)\n",
    "        vutils.save_image(real, os.path.join(\"fake\", f\"{i}.jpg\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
