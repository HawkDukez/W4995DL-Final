{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ee59a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "from numpy import ones\n",
    "from numpy import expand_dims\n",
    "from numpy import log\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import exp\n",
    "from numpy.random import shuffle\n",
    "from keras.datasets import cifar10\n",
    "from skimage.transform import resize\n",
    "from numpy import asarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6885c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import utils as vutils\n",
    "from transformer import VQGANTransformer\n",
    "from utils import load_data, plot_images\n",
    "import sys\n",
    "sys.path.insert(0, '/home/ygong2832/taming-transformers')\n",
    "sys.path.insert(0, '/home/ygong2832/taming-transformers/taming')\n",
    "# import model\n",
    "class Test:\n",
    "    def __init__(self, args):\n",
    "        self.model = VQGANTransformer(args).to(device=args.device)\n",
    "        self.model.load_state_dict(torch.load('path'))  ##? 改path\n",
    "        self.model.eval()\n",
    "        self.calculate_inception_score(args)\n",
    "\n",
    "                \n",
    "   # def scale_images(self,images, new_shape):\n",
    "    #    images_list = list()\n",
    "     #   for image in images:\n",
    "      #      # resize with nearest neighbor interpolation\n",
    "       #     new_image = resize(image, new_shape, 0)\n",
    "        #    # store\n",
    "         #   images_list.append(new_image)\n",
    "        #return asarray(images_list)\n",
    " \n",
    "\n",
    "    def calculate_inception_score(self, n_split=10, eps=1E-16):\n",
    "        image = load_data(args) ## 改arg里数据来源\n",
    "        image=image.to(device=args.device) #?? 可能不需要\n",
    "        shuffle(test_dataset)\n",
    "        \n",
    "        # enumerate splits of images/predictions\n",
    "        scores = list()\n",
    "        n_part = floor(images.shape[0] / n_split)\n",
    "        for i in range(n_split):\n",
    "        \n",
    "            ix_start, ix_end = i * n_part, (i+1) * n_part\n",
    "            subset = images[ix_start:ix_end]\n",
    "        \n",
    "            subset = subset.astype('float32')\n",
    "            # predict p(y|x)\n",
    "            \n",
    "            log, sampled_imgs = self.model.log_images(subset[0][None])\n",
    "            p_yx = sampled_imgs[1] #有可能是2，因为多个图片会多一个维度，rec变为2\n",
    "            \n",
    "            # calculate p(y)\n",
    "            p_y = expand_dims(p_yx.mean(axis=0), 0)\n",
    "            # calculate KL divergence using log probabilities\n",
    "            kl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))\n",
    "            # sum over classes\n",
    "            sum_kl_d = kl_d.sum(axis=1)\n",
    "            # average over images\n",
    "            avg_kl_d = mean(sum_kl_d)\n",
    "            # undo the log\n",
    "            is_score = exp(avg_kl_d)\n",
    "            # store\n",
    "            scores.append(is_score)\n",
    "        # average across images\n",
    "        is_avg, is_std = mean(scores), std(scores)\n",
    "        return is_avg, is_std\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ae4b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=\"VQGAN\")\n",
    "    parser.add_argument('--latent-dim', type=int, default=256, help='Latent dimension n_z.')\n",
    "    parser.add_argument('--image-size', type=int, default=256, help='Image height and width.)')\n",
    "    parser.add_argument('--num-codebook-vectors', type=int, default=1024, help='Number of codebook vectors.')\n",
    "    parser.add_argument('--beta', type=float, default=0.25, help='Commitment loss scalar.')\n",
    "    parser.add_argument('--image-channels', type=int, default=3, help='Number of channels of images.')\n",
    "    parser.add_argument('--dataset-path', type=str, default='./data', help='Path to data.')\n",
    "    parser.add_argument('--checkpoint-path', type=str, default='./checkpoints/last_ckpt.pt', help='Path to checkpoint.')\n",
    "    parser.add_argument('--device', type=str, default=\"cuda\", help='Which device the training is on')\n",
    "    parser.add_argument('--batch-size', type=int, default=10, help='Input batch size for training.')\n",
    "    parser.add_argument('--epochs', type=int, default=50, help='Number of epochs to train.')\n",
    "    parser.add_argument('--learning-rate', type=float, default=2.25e-05, help='Learning rate.')\n",
    "    parser.add_argument('--beta1', type=float, default=0.5, help='Adam beta param.')\n",
    "    parser.add_argument('--beta2', type=float, default=0.9, help='Adam beta param.')\n",
    "    parser.add_argument('--disc-start', type=int, default=10000, help='When to start the discriminator.')\n",
    "    parser.add_argument('--disc-factor', type=float, default=1., help='Weighting factor for the Discriminator.')\n",
    "    parser.add_argument('--l2-loss-factor', type=float, default=1., help='Weighting factor for reconstruction loss.')\n",
    "    parser.add_argument('--perceptual-loss-factor', type=float, default=1., help='Weighting factor for perceptual loss.')\n",
    "    parser.add_argument('--config-path', type=str, default='./configs/model.yaml', help='Path to configs.')\n",
    "\n",
    "    parser.add_argument('--pkeep', type=float, default=0.5, help='Percentage for how much latent codes to keep.')\n",
    "    parser.add_argument('--sos-token', type=int, default=0, help='Start of Sentence token.')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    args.dataset_path = r\"/home/ygong2832/file/ILSVRC/Data/CLS-LOC/train_sub2\"\n",
    "    args.checkpoint_path = r\"./taming-transformers/logs/vqgan_imagenet_f16_16384/checkpoints/last.ckpt\"\n",
    "    args.config_path = r\"./taming-transformers/logs/vqgan_imagenet_f16_16384/configs/model.yaml\"\n",
    "\n",
    "    testpic = Test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c853179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f71f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f850e665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d58a09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def calculate_inception_score(images, n_split=10, eps=1E-16):\n",
    "    \n",
    "    model = ae\n",
    "    # enumerate splits of images/predictions\n",
    "    scores = list()\n",
    "    n_part = floor(images.shape[0] / n_split)\n",
    "    for i in range(n_split):\n",
    "        \n",
    "        ix_start, ix_end = i * n_part, (i+1) * n_part\n",
    "        subset = images[ix_start:ix_end]\n",
    "        \n",
    "        ## for i, imgs in zip(pbar, subset):\n",
    "        \n",
    "        subset = subset.astype('float32')\n",
    "        # predict p(y|x)\n",
    "        p_yx = model.predict(subset)\n",
    "        # calculate p(y)\n",
    "        p_y = expand_dims(p_yx.mean(axis=0), 0)\n",
    "        # calculate KL divergence using log probabilities\n",
    "        kl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))\n",
    "        # sum over classes\n",
    "        sum_kl_d = kl_d.sum(axis=1)\n",
    "        # average over images\n",
    "        avg_kl_d = mean(sum_kl_d)\n",
    "        # undo the log\n",
    "        is_score = exp(avg_kl_d)\n",
    "        # store\n",
    "        scores.append(is_score)\n",
    "    # average across images\n",
    "    is_avg, is_std = mean(scores), std(scores)\n",
    "    return is_avg, is_std\n",
    " \n",
    "\n",
    "\n",
    "shuffle(X_test)\n",
    "is_avg, is_std = calculate_inception_score(X_test)\n",
    "print('score', is_avg, is_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
