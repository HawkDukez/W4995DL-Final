{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d32eee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "Downloading vgg_lpips model from https://heibox.uni-heidelberg.de/f/607503859c864bc1b30b/?dl=1 to taming/modules/autoencoder/lpips/vgg.pth\n",
      "8.19kB [00:00, 73.2kB/s]                                                        \n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "/home/ygong2832/checkpoints/transformer_epoch_39.pt\n",
      "Traceback (most recent call last):\n",
      "  File \"./MaskGIT-pytorch/Calculate_IS.py\", line 150, in <module>\n",
      "    testpic = TestTransformer(args)\n",
      "  File \"./MaskGIT-pytorch/Calculate_IS.py\", line 37, in __init__\n",
      "    self.model = self.load_transformer(args).to(device=args.device)\n",
      "  File \"./MaskGIT-pytorch/Calculate_IS.py\", line 54, in load_transformer\n",
      "    sd = torch.load(args.transformer_checkpoint_path, map_location=\"cpu\")[\"state_dict\"]\n",
      "KeyError: 'state_dict'\n"
     ]
    }
   ],
   "source": [
    "!python ./MaskGIT-pytorch/Calculate_IS.py --batch-size=10 --num-codebook-vectors=16384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38fa65c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar 29 04:53:27 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   44C    P0    67W / 149W |      0MiB / 11441MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0bc6492d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "config_path = r\"./taming-transformers/logs/vqgan_imagenet_f16_16384/configs/model.yaml\"\n",
    "config = OmegaConf.load(config_path)\n",
    "config.model.params['n_embed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc3706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import utils as vutils\n",
    "from transformer import VQGANTransformer\n",
    "from utils import load_data, plot_images\n",
    "import sys\n",
    "sys.path.insert(0, '/home/ygong2832/taming-transformers')\n",
    "sys.path.insert(0, '/home/ygong2832/taming-transformers/taming')\n",
    "# import model\n",
    "model = VQGANTransformer(args).to(device=args.device)\n",
    "model.load_state_dict(torch.load('path'))\n",
    "model.eval()\n",
    "# test\n",
    "with tqdm(range(len(test_dataset))) as pbar:\n",
    "    for i, imgs in zip(pbar, test_dataset):\n",
    "        real = imgs.to(device=args.device)\n",
    "        vutils.save_image(real, os.path.join(\"real\", f\"{i}.jpg\"))\n",
    "        logits, target = model(real)\n",
    "        vutils.save_image(real, os.path.join(\"fake\", f\"{i}.jpg\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
