{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4d32eee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\r\n",
      "python: can't open file './MaskGIT-pytorch/training_transformer.py': [Errno 2] No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!python ./MaskGIT-pytorch/training_transformer.py --batch-size=10 --num-codebook-vectors=16384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d66f4585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "100%|█████████████████| 130/130 [07:58<00:00,  3.68s/it, Transformer_Loss=0.728]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Figure(640x480)\n",
      "100%|██████████████████| 130/130 [07:59<00:00,  3.69s/it, Transformer_Loss=1.19]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Figure(640x480)\n",
      "100%|███████████████████| 130/130 [08:00<00:00,  3.69s/it, Transformer_Loss=5.2]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Figure(640x480)\n",
      "100%|██████████████████| 130/130 [07:59<00:00,  3.69s/it, Transformer_Loss=5.92]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Figure(640x480)\n",
      "100%|█████████████████| 130/130 [07:59<00:00,  3.69s/it, Transformer_Loss=0.117]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Figure(640x480)\n"
     ]
    }
   ],
   "source": [
    "!python ./MaskGIT-pytorch/training_transformer.py --batch-size=10 --num-codebook-vectors=16384 --epochs=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38fa65c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar 29 04:53:27 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   44C    P0    67W / 149W |      0MiB / 11441MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3e17230",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.yaml\r\n"
     ]
    }
   ],
   "source": [
    "ls ./taming-transformers/logs/vqgan_imagenet_f16_16384/configs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0bc6492d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "config_path = r\"./taming-transformers/logs/vqgan_imagenet_f16_16384/configs/model.yaml\"\n",
    "config = OmegaConf.load(config_path)\n",
    "config.model.params['n_embed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc3706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import utils as vutils\n",
    "from transformer import VQGANTransformer\n",
    "from utils import load_data, plot_images\n",
    "import sys\n",
    "sys.path.insert(0, '/home/ygong2832/taming-transformers')\n",
    "sys.path.insert(0, '/home/ygong2832/taming-transformers/taming')\n",
    "# import model\n",
    "model = VQGANTransformer(args).to(device=args.device)\n",
    "model.load_state_dict(torch.load('path'))\n",
    "model.eval()\n",
    "# test\n",
    "with tqdm(range(len(test_dataset))) as pbar:\n",
    "    for i, imgs in zip(pbar, test_dataset):\n",
    "        real = imgs.to(device=args.device)\n",
    "        vutils.save_image(real, os.path.join(\"real\", f\"{i}.jpg\"))\n",
    "        logits, target = model(real)\n",
    "        vutils.save_image(real, os.path.join(\"fake\", f\"{i}.jpg\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
